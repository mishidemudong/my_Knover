# job settings
job_script="./scripts/distributed/train.sh"

# task settings
#model=UnifiedTransformer
model=Plato
#model=NSPModel
task=DialogGeneration
#task=NextSentencePrediction

#do_generation="true"
#do_generation=True
vocab_path="./config/vocab.txt"
spm_model_file="./config/spm.model"
train_file="data/train.txt"
valid_file="data/valid.txt"
data_format="numerical"
file_format="file"
config_path="./config/12L.json"

# training settings
#init_params="12L"
#init_params="./output/step_13000"
init_checkpoint='./plato_model/step1027-2'
in_tokens="true"
#batch_size=8192
batch_size=8192
lr=1e-5
warmup_steps=1000
weight_decay=0.01
num_epochs=20

train_args="--max_src_len 384 --max_tgt_len 128 --max_seq_len 512"

log_steps=100
validation_steps=2000
save_steps=500

log_dir="./log"
save_path="./plato_model"
